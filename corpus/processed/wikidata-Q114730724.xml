<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<oai_dc:dc xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
  <dc:identifier>https://scholia.toolforge.org/work/Q114730724</dc:identifier>
  <dc:identifier>http://www.wikidata.org/entity/Q114730724</dc:identifier>
  <dc:identifier>doi:10.3390/ROBOTICS11040068</dc:identifier>
  <dc:title>Sensor Fusion with Deep Learning for Autonomous Classification and Management of Aquatic Invasive Plant Species</dc:title>
  <dc:creator>Perrin, Jackson E.</dc:creator>
  <dc:creator>Jernigan, Shaphan R.</dc:creator>
  <dc:creator>Thayer, Jacob D.</dc:creator>
  <dc:creator>Howell, Andrew W.</dc:creator>
  <dc:creator>Leary, James K.</dc:creator>
  <dc:creator>Buckner, Gregory</dc:creator>
  <dc:type>journal article</dc:type>
  <dc:date>2022-06-28</dc:date>
  <dc:rights>https://creativecommons.org/licenses/by/4.0/</dc:rights>
  <dc:subject>theme:invasion management</dc:subject>
  <dc:subject>theme:wikidata.org/entity/Q113019190</dc:subject>
  <dc:subject>invasive plant</dc:subject>
  <dc:subject>invasion management</dc:subject>
  <dc:publisher>MDPI AG</dc:publisher>
  <dc:description>Recent advances in deep learning, including the development of AlexNet, Residual Network (ResNet), and transfer learning, offer unprecedented classification accuracy in the field of machine vision. A developing application of deep learning is the automated identification and management of aquatic invasive plants. Classification of submersed aquatic vegetation (SAV) presents a unique challenge, namely, the lack of a single source of sensor data that can produce robust, interpretable images across a variable range of depth, turbidity, and lighting conditions. This paper focuses on the development of a multi-sensor (RGB and hydroacoustic) classification system for SAV that is robust to environmental conditions and combines the strengths of each sensing modality. The detection of invasive Hydrilla verticillata (hydrilla) is the primary goal. Over 5000 aerial RGB and hydroacoustic images were generated from two Florida lakes via an unmanned aerial vehicle and boat-mounted sonar unit, and tagged for neural network training and evaluation. Classes included “HYDR”, containing hydrilla; “NONE”, lacking SAV, and “OTHER”, containing SAV other than hydrilla. Using a transfer learning approach, deep neural networks with the ResNet architecture were individually trained on the RGB and hydroacoustic datasets. Multiple data fusion methodologies were evaluated to ensemble the outputs of these neural networks for optimal classification accuracy. A method incorporating logic and a Monte Carlo dropout approach yielded the best overall classification accuracy (84%), with recall and precision of 84.5% and 77.5%, respectively, for the hydrilla class. The training and ensembling approaches were repeated for a DenseNet model with identical training and testing datasets. The overall classification accuracy was similar between the ResNet and DenseNet models when averaged across all approaches (1.9% higher accuracy for the ResNet vs. the DenseNet).</dc:description>
</oai_dc:dc>